import streamlit as st
import pandas as pd
from typing import Optional, List, Dict
from datetime import datetime
from engines.ai_engine import AIEngine
from core.i18n_block import I18nBlock
from core.config_block import ConfigBlock
from supabase import create_client, Client


class HistoryFeature:
    """
    Nháº­t kÃ½ Hoáº¡t Ä‘á»™ng - Äá»“ng bá»™ vá»›i Supabase + Upload CSV
    
    Features:
    - Upload CSV/Excel history cÅ© tá»« Supabase export
    - Auto-sync vá»›i logs má»›i
    - Filter + Search + Export
    """
    
    def __init__(
        self,
        ai_engine: AIEngine,
        i18n: Optional[I18nBlock] = None,
        config: Optional[ConfigBlock] = None
    ):
        self.ai = ai_engine
        self.i18n = i18n
        self.config = config
        
        # Káº¿t ná»‘i Supabase
        self.db: Optional[Client] = None
        self.connected = False
        
        try:
            url = st.secrets.get("supabase", {}).get("url")
            key = st.secrets.get("supabase", {}).get("key")
            
            if url and key:
                self.db = create_client(url, key)
                self.connected = True
        
        except Exception as e:
            st.warning(f"âš ï¸ KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Supabase: {str(e)}")
    
    def t(self, key: str, default: str = None) -> str:
        if self.i18n:
            return self.i18n.t(key, default or key)
        return default or key
    
    def get_history(
        self,
        limit: int = 50,
        event_type: Optional[str] = None,
        search_term: Optional[str] = None
    ) -> List[Dict]:
        """Láº¥y lá»‹ch sá»­ tá»« Supabase"""
        if not self.connected:
            return []
        
        try:
            query = self.db.table("history_logs").select("*")
            
            # Filter by type
            if event_type and event_type != "all":
                query = query.eq("type", event_type)
            
            # Search in title/content
            if search_term:
                query = query.or_(
                    f"title.ilike.%{search_term}%,"
                    f"content.ilike.%{search_term}%"
                )
            
            # Order by newest first
            response = query.order("created_at", desc=True).limit(limit).execute()
            
            return response.data or []
        
        except Exception as e:
            st.error(f"âŒ Lá»—i Ä‘á»c Supabase: {str(e)}")
            return []
    
    def upload_csv_to_supabase(self, uploaded_file) -> int:
        """
        Upload CSV/Excel history cÅ© vÃ o Supabase
        
        Returns:
            Sá»‘ lÆ°á»£ng records Ä‘Ã£ import thÃ nh cÃ´ng
        """
        if not self.connected:
            st.error("âŒ KhÃ´ng káº¿t ná»‘i Supabase")
            return 0
        
        try:
            # Äá»c file
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.info(f"ğŸ“Š PhÃ¡t hiá»‡n {len(df)} dÃ²ng trong file")
            
            # Mapping columns (adjust theo export Supabase cá»§a chá»‹)
            column_mapping = {
                'id': 'original_id',
                'created_at': 'created_at',
                'type': 'type',
                'title': 'title',
                'content': 'content',
                'user_name': 'user_name',
                'sentiment_score': 'sentiment_score',
                'sentiment_label': 'sentiment_label'
            }
            
            # Rename columns
            df_renamed = df.rename(columns=column_mapping)
            
            # Required columns
            required = ['created_at', 'type', 'title', 'content']
            missing = [col for col in required if col not in df_renamed.columns]
            
            if missing:
                st.error(f"âŒ File thiáº¿u cá»™t: {', '.join(missing)}")
                return 0
            
            # Convert to list of dicts
            records = df_renamed[required + ['user_name', 'sentiment_score', 'sentiment_label']].fillna('').to_dict('records')
            
            # Batch insert (Supabase giá»›i háº¡n ~1000 rows/request)
            batch_size = 500
            success_count = 0
            
            progress_bar = st.progress(0)
            
            for i in range(0, len(records), batch_size):
                batch = records[i:i+batch_size]
                
                try:
                    # Insert batch
                    response = self.db.table("history_logs").insert(batch).execute()
                    success_count += len(batch)
                    
                    # Update progress
                    progress = min(1.0, (i + batch_size) / len(records))
                    progress_bar.progress(progress)
                
                except Exception as e:
                    st.warning(f"âš ï¸ Lá»—i batch {i//batch_size + 1}: {str(e)}")
                    continue
            
            progress_bar.empty()
            return success_count
        
        except Exception as e:
            st.error(f"âŒ Lá»—i xá»­ lÃ½ file: {str(e)}")
            return 0
    
    def render(self):
        """Render History UI"""
        st.title("â³ Nháº­t KÃ½ Hoáº¡t Äá»™ng")
        st.caption("Quáº£n lÃ½ lá»‹ch sá»­ phÃ¢n tÃ­ch & tranh biá»‡n")
        
        if not self.connected:
            st.error("âŒ KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Supabase. Kiá»ƒm tra secrets.toml")
            return
        
        # ===== SECTION 1: UPLOAD CSV =====
        with st.expander("ğŸ“¤ Import Lá»‹ch Sá»­ CÅ© (CSV/Excel)", expanded=False):
            st.markdown("""
            **HÆ°á»›ng dáº«n:**
            1. Export dá»¯ liá»‡u tá»« Supabase (Table Editor â†’ Export CSV)
            2. Upload file vÃ o Ä‘Ã¢y
            3. Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng merge vá»›i logs má»›i
            
            **LÆ°u Ã½:** File cáº§n cÃ³ cÃ¡c cá»™t: `created_at`, `type`, `title`, `content`
            """)
            
            uploaded = st.file_uploader(
                "Chá»n file CSV hoáº·c Excel",
                type=["csv", "xlsx"],
                help="File export tá»« Supabase"
            )
            
            if uploaded:
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    # Preview
                    try:
                        if uploaded.name.endswith('.csv'):
                            preview_df = pd.read_csv(uploaded, nrows=5)
                        else:
                            preview_df = pd.read_excel(uploaded, nrows=5)
                        
                        st.markdown("**Preview 5 dÃ²ng Ä‘áº§u:**")
                        st.dataframe(preview_df, use_container_width=True)
                    except Exception as e:
                        st.error(f"âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file: {str(e)}")
                
                with col2:
                    if st.button("ğŸš€ Import", type="primary", use_container_width=True):
                        with st.spinner("â³ Äang import..."):
                            uploaded.seek(0)  # Reset file pointer
                            success = self.upload_csv_to_supabase(uploaded)
                            
                            if success > 0:
                                st.success(f"âœ… ÄÃ£ import {success} records!")
                                st.balloons()
                                st.rerun()
                            else:
                                st.error("âŒ Import tháº¥t báº¡i")
        
        st.divider()
        
        # ===== SECTION 2: FILTERS =====
        col1, col2, col3, col4 = st.columns([2, 2, 2, 1])
        
        with col1:
            event_filter = st.selectbox(
                "ğŸ” Lá»c theo loáº¡i:",
                ["all", "book_analysis", "debate", "translation", "voice"],
                format_func=lambda x: {
                    "all": "ğŸ“‹ Táº¥t cáº£",
                    "book_analysis": "ğŸ“š PhÃ¢n tÃ­ch sÃ¡ch",
                    "debate": "ğŸ—£ï¸ Tranh biá»‡n",
                    "translation": "âœï¸ Dá»‹ch thuáº­t",
                    "voice": "ğŸ™ï¸ Voice"
                }.get(x, x)
            )
        
        with col2:
            search = st.text_input(
                "ğŸ” TÃ¬m kiáº¿m:",
                placeholder="TÃ¬m trong title/content..."
            )
        
        with col3:
            limit = st.number_input(
                "ğŸ“Š Sá»‘ lÆ°á»£ng:",
                min_value=10,
                max_value=500,
                value=50,
                step=10
            )
        
        with col4:
            st.markdown("<br>", unsafe_allow_html=True)  # Spacing
            if st.button("ğŸ”„", use_container_width=True, help="Táº£i láº¡i"):
                st.rerun()
        
        st.divider()
        
        # ===== SECTION 3: LOAD & DISPLAY =====
        with st.spinner("ğŸ“¡ Äang táº£i tá»« Supabase..."):
            history = self.get_history(
                limit=limit,
                event_type=event_filter if event_filter != "all" else None,
                search_term=search if search.strip() else None
            )
        
        if history:
            # Stats
            col1, col2, col3, col4 = st.columns(4)
            
            # Count by type
            types_count = {}
            for log in history:
                t = log.get("type", "unknown")
                types_count[t] = types_count.get(t, 0) + 1
            
            col1.metric("ğŸ“ Tá»•ng", len(history))
            col2.metric("ğŸ“š SÃ¡ch", types_count.get("book_analysis", 0))
            col3.metric("ğŸ—£ï¸ Tranh biá»‡n", types_count.get("debate", 0))
            col4.metric("âœï¸ Dá»‹ch", types_count.get("translation", 0))
            
            st.divider()
            
            # Export button
            col1, col2 = st.columns([4, 1])
            with col2:
                if st.button("ğŸ’¾ Export CSV", use_container_width=True):
                    df_export = pd.DataFrame(history)
                    csv = df_export.to_csv(index=False)
                    
                    st.download_button(
                        label="â¬‡ï¸ Táº£i xuá»‘ng",
                        data=csv,
                        file_name=f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
            
            st.divider()
            
            # Display logs
            st.markdown("### ğŸ“œ Danh sÃ¡ch Log")
            
            for entry in history:
                event_type = entry.get("type", "unknown")
                created_at = entry.get("created_at", "N/A")
                title = entry.get("title", "Untitled")
                user = entry.get("user_name", "Guest")
                content = entry.get("content", "")
                sentiment = entry.get("sentiment_label", "")
                
                # Icon theo loáº¡i
                icon_map = {
                    "book_analysis": "ğŸ“š",
                    "debate": "ğŸ—£ï¸",
                    "translation": "âœï¸",
                    "voice": "ğŸ™ï¸"
                }
                icon = icon_map.get(event_type, "ğŸ“„")
                
                # Sentiment badge
                sentiment_badge = ""
                if sentiment:
                    color_map = {
                        "HÃ o há»©ng": "ğŸŸ¢",
                        "Trung tÃ­nh": "ğŸŸ¡",
                        "TiÃªu cá»±c": "ğŸ”´"
                    }
                    sentiment_badge = color_map.get(sentiment, "")
                
                # Expander
                with st.expander(
                    f"{icon} **{title}** {sentiment_badge} â€¢ {created_at[:16]} â€¢ {user}",
                    expanded=False
                ):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.markdown(f"**Loáº¡i:** {event_type}")
                        st.markdown(f"**NgÆ°á»i dÃ¹ng:** {user}")
                        st.markdown(f"**Thá»i gian:** {created_at}")
                        if sentiment:
                            st.markdown(f"**Cáº£m xÃºc:** {sentiment} (score: {entry.get('sentiment_score', 0):.2f})")
                    
                    with col2:
                        # AI Provider badge (náº¿u cÃ³)
                        if "provider" in entry:
                            provider = entry["provider"]
                            provider_icon = {
                                "gemini": "ğŸŸ¡",
                                "grok": "ğŸŸ¢",
                                "deepseek": "ğŸŸ£"
                            }.get(provider, "âš«")
                            st.info(f"{provider_icon} {provider.upper()}")
                    
                    st.divider()
                    st.markdown("**Ná»™i dung:**")
                    
                    # Truncate long content
                    if len(content) > 2000:
                        st.markdown(content[:2000] + "...")
                        with st.expander("ğŸ“– Xem toÃ n bá»™"):
                            st.markdown(content)
                    else:
                        st.markdown(content)
        
        else:
            st.info("ğŸ“­ ChÆ°a cÃ³ log nÃ o. HÃ£y báº¯t Ä‘áº§u phÃ¢n tÃ­ch hoáº·c tranh biá»‡n!")
    
    @staticmethod
    def log_event(
        event_type: str,
        title: str,
        content: str,
        provider: Optional[str] = None,
        sentiment_score: Optional[float] = None,
        sentiment_label: Optional[str] = None
    ):
        """
        Static method Ä‘á»ƒ log tá»« báº¥t ká»³ module nÃ o
        
        Args:
            event_type: book_analysis, debate, translation, voice
            title: TiÃªu Ä‘á»
            content: Ná»™i dung chi tiáº¿t
            provider: AI provider (gemini, grok, deepseek)
            sentiment_score: Äiá»ƒm cáº£m xÃºc (0-1)
            sentiment_label: NhÃ£n cáº£m xÃºc
        """
        try:
            from supabase import create_client
            
            url = st.secrets.get("supabase", {}).get("url")
            key = st.secrets.get("supabase", {}).get("key")
            
            if url and key:
                db = create_client(url, key)
                
                data = {
                    "type": event_type,
                    "title": title,
                    "content": content,
                    "user_name": st.session_state.get("current_user", "Guest")
                }
                
                # Optional fields
                if provider:
                    data["provider"] = provider
                if sentiment_score is not None:
                    data["sentiment_score"] = sentiment_score
                if sentiment_label:
                    data["sentiment_label"] = sentiment_label
                
                db.table("history_logs").insert(data).execute()
        
        except Exception:
            pass  # Silent fail
